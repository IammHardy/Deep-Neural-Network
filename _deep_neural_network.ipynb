{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3478d704-54cc-4ff8-9e44-26435b4b1a8c",
      "metadata": {
        "id": "3478d704-54cc-4ff8-9e44-26435b4b1a8c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(self.n_nodes2)\n",
        "        self.optimizer = optimizer\n",
        "        self.HW = 0\n",
        "        self.HB = 0\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z = X\n",
        "        self.A = X @ self.W + self.B\n",
        "        return self.A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.Z.T @ dA\n",
        "        self.dZ = dA @ self.W.T\n",
        "        self = self.optimizer.update(self)\n",
        "\n",
        "         # Update weights and biases using the optimizer\n",
        "        #self.W, self.B = self.optimizer.update(self.W, self.B, self.dW, self.dB)\n",
        "\n",
        "        return self.dZ"
      ],
      "metadata": {
        "id": "ptxpCAU2_3MS"
      },
      "id": "ptxpCAU2_3MS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "9YYvj3FD_6Lr"
      },
      "id": "9YYvj3FD_6Lr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
        "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "kHJbKCn-_9fA"
      },
      "id": "kHJbKCn-_9fA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = 1 / (1 + np.exp(-self.A))\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "tmMSE-Nw__uR"
      },
      "id": "tmMSE-Nw__uR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.tanh(self.A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "khUO-boBACg8"
      },
      "id": "khUO-boBACg8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax:\n",
        "\n",
        "    def forward(self, A):\n",
        "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, Z, y):\n",
        "        dA = Z - y\n",
        "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
        "        return dA, loss"
      ],
      "metadata": {
        "id": "xERE50_eAFbU"
      },
      "id": "xERE50_eAFbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.maximum(0, A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "R-w0bEmvAI7f"
      },
      "id": "R-w0bEmvAI7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        _ = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "loMKpjxEAMui"
      },
      "id": "loMKpjxEAMui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        _ = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = np.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "RhcBIYK8AQVy"
      },
      "id": "RhcBIYK8AQVy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.HW += layer.dW * layer.dW\n",
        "        layer.HB += layer.dB * layer.dB\n",
        "        delta = 1e-7\n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "6ijyciAYATbi"
      },
      "id": "6ijyciAYATbi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "metadata": {
        "id": "r_JJpgTSAYQJ"
      },
      "id": "r_JJpgTSAYQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.n_features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.n_output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activater = activater\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                A1 = self.FC1.forward(mini_X)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                #print(Z2.shape)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1)\n",
        "\n",
        "            if self.verbose:\n",
        "                A1 = self.FC1.forward(X)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
        "\n",
        "                if X_val is not None:\n",
        "                    A1 = self.FC1.forward(X_val)\n",
        "                    Z1 = self.activation1.forward(A1)\n",
        "                    A2 = self.FC2.forward(Z1)\n",
        "                    Z2 = self.activation2.forward(A2)\n",
        "                    A3 = self.FC3.forward(Z2)\n",
        "                    Z3 = self.activation3.forward(A3)\n",
        "                    self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
        "\n",
        "    def predict(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        return np.argmax(Z3, axis=1)"
      ],
      "metadata": {
        "id": "b7VKIA9MAbKL"
      },
      "id": "b7VKIA9MAbKL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float64)\n",
        "X_test = X_test.astype(np.float64)\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "Hb1IIGVzAfNT"
      },
      "id": "Hb1IIGVzAfNT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "EyHVaMtWAnKv"
      },
      "id": "EyHVaMtWAnKv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
      ],
      "metadata": {
        "id": "NxagQgn3Ap3E",
        "outputId": "cfff8770-b01a-4203-c419-303c36371a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NxagQgn3Ap3E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN = ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU)\n",
        "\n",
        "SDNN.fit(X_train, y_train_one_hot, X_val, y_test_one_hot)"
      ],
      "metadata": {
        "id": "V0usSPqBAtJ-"
      },
      "id": "V0usSPqBAtJ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4HkB24_n5o",
        "outputId": "618217d5-891a-42c7-b254-63dc19049a0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9800833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "pred = SDNN.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "id": "Wr4HkB24_n5o"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}